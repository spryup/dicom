{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T20:10:42.920986Z",
     "start_time": "2019-08-11T20:10:42.771587Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pymongo import MongoClient, InsertOne, DeleteMany, ReplaceOne, UpdateOne\n",
    "import gridfs\n",
    "import re\n",
    "\n",
    "client = MongoClient(host=['localhost:27017'])\n",
    "#client=MongoClient(\"mongodb://Admin:admin@54.191.161.228\")\n",
    "db = client.DICOM\n",
    "collection=db['dicom_data']\n",
    "fs = gridfs.GridFS(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T20:13:07.561106Z",
     "start_time": "2019-08-11T20:13:00.034747Z"
    }
   },
   "outputs": [],
   "source": [
    "temp=[]\n",
    "for e,i in enumerate(fs.find({})):\n",
    "#     print(i.image_clean)\n",
    "#     z = np.frombuffer(i.image_clean, dtype=np.uint8)\n",
    "#     x=z.reshape( tuple(i.shape))\n",
    "    temp+=i.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T20:16:31.370344Z",
     "start_time": "2019-08-11T20:16:31.359842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 408),\n",
       " ('uterus', 308),\n",
       " ('u_bladder', 187),\n",
       " ('rt_kidney', 185),\n",
       " ('heart', 167),\n",
       " ('gb', 113),\n",
       " ('cx', 110),\n",
       " ('foetus', 105),\n",
       " ('lt_kidney', 104),\n",
       " ('pv', 100),\n",
       " ('liver', 99),\n",
       " ('cbd', 99),\n",
       " ('lt_lobe', 98),\n",
       " ('pancreas', 95),\n",
       " ('femur', 78),\n",
       " ('trunk', 74),\n",
       " ('spine', 72),\n",
       " ('rt_ovary', 71),\n",
       " ('placenta', 69),\n",
       " ('lt_ovary', 69),\n",
       " ('cervix', 62),\n",
       " ('spleen', 54),\n",
       " ('gs', 50),\n",
       " ('cal', 45),\n",
       " ('prostate', 38),\n",
       " ('cephalic', 30),\n",
       " ('breech', 24),\n",
       " ('cyst', 20),\n",
       " ('breast', 12),\n",
       " ('fib', 12),\n",
       " ('rif_region', 9),\n",
       " ('vag', 9),\n",
       " ('umbilical_region', 8),\n",
       " ('hydroneph', 6),\n",
       " ('foot', 6),\n",
       " ('hands', 5),\n",
       " ('nipple', 4),\n",
       " ('ascites', 4),\n",
       " ('rp', 4),\n",
       " ('aorta', 3),\n",
       " ('fibroid', 2),\n",
       " ('pe', 2),\n",
       " ('dilated_ihds', 1),\n",
       " ('worms', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c=Counter(temp)\n",
    "c=sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T20:44:44.575251Z",
     "start_time": "2019-08-11T20:44:42.900474Z"
    }
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "import numpy as np\n",
    "for e,i in enumerate(fs.find({})):\n",
    "    z = np.frombuffer(i.image_clean, dtype=np.uint8)\n",
    "    x=z.reshape(tuple(i.shape))\n",
    "    #print(tuple(i.shape))\n",
    "    ## need to find a way\n",
    "    if [768,1024] == i.shape:\n",
    "        lab=i.labels\n",
    "        if 'uterus' in lab:\n",
    "            data.append(x)\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            data.append(x)\n",
    "            labels.append(0)\n",
    "data=np.array(data)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "    from keras import backend as K\n",
    "    import keras\n",
    "    print(K.image_data_format())\n",
    "    # import tensorflow.compat.v1 as tf\n",
    "    # tf.disable_v2_behavior()\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(5, kernel_size=(3, 3),activation='relu',input_shape=(768,1024,1), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 768, 1024, 5)      50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 384, 512, 5)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 384, 512, 5)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 983040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 983040)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1966082   \n",
      "=================================================================\n",
      "Total params: 1,966,132\n",
      "Trainable params: 1,966,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amrit/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/amrit/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "W0827 19:43:41.559621 4671038912 deprecation.py:323] From /Users/amrit/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 609 samples, validate on 153 samples\n",
      "Epoch 1/3\n",
      "609/609 [==============================] - 66s 109ms/step - loss: 1.7023 - acc: 0.8243 - val_loss: 1.0882 - val_acc: 0.8562\n",
      "Epoch 2/3\n",
      "609/609 [==============================] - 65s 106ms/step - loss: 0.6119 - acc: 0.8588 - val_loss: 0.4976 - val_acc: 0.8105\n",
      "Epoch 3/3\n",
      "609/609 [==============================] - 66s 108ms/step - loss: 0.4657 - acc: 0.8227 - val_loss: 0.4517 - val_acc: 0.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131c54320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from keras.utils import np_utils\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(data, labels):\n",
    "#     train_data, test_data=df.iloc[train_index], df.iloc[test_index]\n",
    "#     train_data, train_label = train_data[train_data.col umns[:-1]].values, train_data[train_data.columns[-1]].values\n",
    "#     test_data, test_label = test_data[test_data.columns[:-1]].values, test_data[test_data.columns[-1]].values\n",
    "    train_data, train_label = data[[train_index]], labels[train_index]\n",
    "    test_data, test_label = data[[test_index]], labels[test_index]\n",
    "    X_train = train_data.reshape(train_data.shape[0], 768, 1024,1)\n",
    "    X_test = test_data.reshape(test_data.shape[0],  768, 1024,1)\n",
    "\n",
    "#     X_train = X_train.astype('float32')\n",
    "#     X_test = X_test.astype('float32')\n",
    "    \n",
    "#     X_train/=255\n",
    "#     X_test/=255\n",
    "\n",
    "    train_label = np_utils.to_categorical(train_label, 2)\n",
    "    test_label = np_utils.to_categorical(test_label,2)\n",
    "    #print(test_label.shape)\n",
    "    #model.fit(train_data, train_label, epochs=10, validation_data=(test_data, test_label))\n",
    "    break\n",
    "model.fit(X_train, train_label, epochs=3, validation_data=(X_test, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.reset_uids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.get_uid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
