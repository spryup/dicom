{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:10:43.927359Z",
     "start_time": "2019-10-03T01:10:43.739596Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pymongo import MongoClient, InsertOne, DeleteMany, ReplaceOne, UpdateOne\n",
    "import gridfs\n",
    "import re\n",
    "\n",
    "client = MongoClient(host=['localhost:27017'])\n",
    "#client=MongoClient(\"mongodb://Admin:admin@54.191.161.228\")\n",
    "db = client.DICOM\n",
    "collection=db['dicom_data']\n",
    "fs = gridfs.GridFS(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:10:44.448875Z",
     "start_time": "2019-10-03T01:10:44.443199Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp=[]\n",
    "# for e,i in enumerate(fs.find({})):\n",
    "# #     print(i.image_clean)\n",
    "# #     z = np.frombuffer(i.image_clean, dtype=np.uint8)\n",
    "# #     x=z.reshape( tuple(i.shape))\n",
    "#     temp+=i.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:10:45.046815Z",
     "start_time": "2019-10-03T01:10:45.042945Z"
    }
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# c=Counter(temp)\n",
    "# c=sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:11:12.243912Z",
     "start_time": "2019-10-03T01:10:45.867054Z"
    }
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "# data1=[]\n",
    "# labels2=[]\n",
    "import numpy as np\n",
    "for e,i in enumerate(fs.find({})):\n",
    "    z = np.frombuffer(i.image_clean, dtype=np.uint8)\n",
    "    x=z.reshape(tuple(i.shape))\n",
    "    #print(tuple(i.shape))\n",
    "    ## need to find a way\n",
    "    lab=i.labels\n",
    "    if [768,1024] == i.shape and 'others' not in lab:\n",
    "        for j in lab:\n",
    "            data.append(x)\n",
    "            labels.append(j)\n",
    "#     if [768,512] == i.shape and 'others' not in lab:\n",
    "#         for j in lab:\n",
    "#             data1.append(x)\n",
    "#             labels1.append(j)\n",
    "data=np.array(data)\n",
    "labels=np.array(labels)\n",
    "# data1=np.array(data1)\n",
    "# labels1=np.array(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:11:12.286802Z",
     "start_time": "2019-10-03T01:11:12.279129Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_dic_str_to_index(labels,labels1):\n",
    "#     return list(set(labels.tolist())) + list(set(labels1.tolist()))\n",
    "\n",
    "# one_hot=build_dic_str_to_index(labels,labels1)\n",
    "# n_classes=len(set(labels.tolist())) + len(set(labels1.tolist()))\n",
    "def build_dic_str_to_index(labels):\n",
    "    return list(set(labels.tolist()))\n",
    "\n",
    "one_hot=build_dic_str_to_index(labels)\n",
    "n_classes=len(set(labels.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:11:12.363059Z",
     "start_time": "2019-10-03T01:11:12.312878Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:36:56.117724Z",
     "start_time": "2019-10-03T01:36:56.073085Z"
    },
    "code_folding": [
     18,
     36,
     54,
     71,
     89,
     107,
     125
    ]
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "from keras.layers.merge import concatenate\n",
    "# print(K.image_data_format())\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# I nearly always recommend batch normalization because it tends to stabilize training and make tuning hyperparameters easier. \n",
    "# That said, it can double or triple your training time. Use it wisely.\n",
    "# Decreasing Dropout help. its purpose is to help your network generalize and not overfit.\n",
    "# increasing pool size doesn't help.\n",
    "# reducing kernel size didnt help. Increasing it, increases the training time.\n",
    "\n",
    "def modelbuilding(): # 13, 17%\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=7,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    #model.add(MaxPooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding1(): # 2.6 loss Acc 41%\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=7,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    #model.add(MaxPooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding2(): # 2.7, 40\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=7,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    #model.add(MaxPooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding3(): # 2.9, 39\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=7,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    model.add(MaxPooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding4(): # 2.1, 41 \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=7,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    model.add(AveragePooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding5(): # 4.1, 27 \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=7,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=3))\n",
    "    model.add(Conv2D(64, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=3))\n",
    "    model.add(Conv2D(128, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    model.add(AveragePooling2D(pool_size=4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding6(): # 2.6, 38 \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=11,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, kernel_size=9,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=7,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    model.add(AveragePooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding7(): # 2.4, 39  \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=9,strides=(2, 2),activation='relu',input_shape=(768,1024,1)\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(128, kernel_size=7,strides=(2, 2),activation='relu'\n",
    "              ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005)))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(256, kernel_size=5,strides=(2, 2),activation='relu'\n",
    "                     ,padding=\"same\",kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.0005))) ## reduce output volume using strided or maxpooling for padding.\n",
    "    model.add(AveragePooling2D(pool_size=3))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modelbuilding8(): #   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:36:56.286487Z",
     "start_time": "2019-10-03T01:36:56.168422Z"
    }
   },
   "outputs": [],
   "source": [
    "model = modelbuilding4()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:28:17.072208Z",
     "start_time": "2019-10-03T01:28:17.065536Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_str_to_one_hot_encoding(convert, one_hot):\n",
    "    length=len(one_hot)\n",
    "    labels=[]\n",
    "    for i in convert:\n",
    "        temp=[0]*length\n",
    "        temp[one_hot.index(i)]=1\n",
    "        labels.append(temp)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:28:25.764178Z",
     "start_time": "2019-10-03T01:28:18.393306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amrit/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/amrit/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  import sys\n",
      "/Users/amrit/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from keras.utils import np_utils\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(data, labels):\n",
    "    train_data, train_label = data[[train_index]], labels[train_index]\n",
    "    test_data, test_label = data[[test_index]], labels[test_index]\n",
    "    X_train = train_data.reshape(train_data.shape[0], 768, 1024,1)\n",
    "    X_test = test_data.reshape(test_data.shape[0],  768, 1024,1)\n",
    "    train_label = convert_str_to_one_hot_encoding(train_label,one_hot)\n",
    "    test_label = convert_str_to_one_hot_encoding(test_label,one_hot)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-03T01:37:17.129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3477 samples, validate on 890 samples\n",
      "Epoch 1/1\n",
      "2176/3477 [=================>............] - ETA: 2:53 - loss: 2.3483 - acc: 0.3755"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, train_label, epochs=1, validation_data=(X_test, test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.reset_uids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.get_uid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(128, kernel_size=6,activation='relu',input_shape=(768,1024,1)))\n",
    "# #model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "# model.add(Conv2D(64, kernel_size=3,activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=3))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(n_classes, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T00:46:40.897527Z",
     "start_time": "2019-09-02T00:46:40.891153Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user\n",
    "# !jupyter nbextensions_configurator enable --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
